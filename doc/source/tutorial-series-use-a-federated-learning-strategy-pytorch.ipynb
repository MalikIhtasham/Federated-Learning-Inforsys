{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr3eehCv-UOt"
      },
      "source": [
        "# Use a federated learning strategy\n",
        "\n",
        "Welcome to the next part of the federated learning tutorial. In previous parts of this tutorial, we introduced federated learning with PyTorch and Flower ([part 1](https://flower.dev/docs/framework/tutorial-get-started-with-flower-pytorch.html)).\n",
        "\n",
        "In this notebook, we'll begin to customize the federated learning system we built in the introductory notebook (again, using [Flower](https://flower.dev/) and [PyTorch](https://pytorch.org/)).\n",
        "\n",
        "> [Star Flower on GitHub](https://github.com/adap/flower) â­ï¸ and join the Flower community on Slack to connect, ask questions, and get help: [Join Slack](https://flower.dev/join-slack) ðŸŒ¼ We'd love to hear from you in the `#introductions` channel! And if anything is unclear, head over to the `#questions` channel.\n",
        "\n",
        "Let's move beyond FedAvg with Flower strategies!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joao-zZj-UO3"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Before we begin with the actual code, let's make sure that we have everything we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_buTtC0B-UO4"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "First, we install the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hAQRslPt-UO6",
        "outputId": "aa2ff9dd-d9ae-4d13-8317-a50dedc89d2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5-iBcih-UO8"
      },
      "source": [
        "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tHKMF3Fo-UO8",
        "outputId": "ea92505d-d7c4-4c6a-e1e2-ecad1e536cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.1.0+cu118 and Flower 1.6.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfbdfzM7-UO9"
      },
      "source": [
        "It is possible to switch to a runtime that has GPU acceleration enabled (on Google Colab: `Runtime > Change runtime type > Hardware acclerator: GPU > Save`). Note, however, that Google Colab is not always able to offer GPU acceleration. If you see an error related to GPU availability in one of the following sections, consider switching back to CPU-based execution by setting `DEVICE = torch.device(\"cpu\")`. If the runtime has GPU acceleration enabled, you should see the output `Training on cuda`, otherwise it'll say `Training on cpu`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tMoI_lg-UO-"
      },
      "source": [
        "### Data loading\n",
        "\n",
        "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap everything in their own `DataLoader`. We introduce a new parameter `num_clients` which allows us to call `load_datasets` with different numbers of clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JliLKdEK-UO-",
        "outputId": "a6b7f967-5351-470f-ff9c-29ffe5c7b3fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:02<00:00, 78927789.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = 10\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXhKX094-UO_"
      },
      "source": [
        "### Model training/evaluation\n",
        "\n",
        "Let's continue with the usual model definition (including `set_parameters` and `get_parameters`), training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GsvZTp4--UPA"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-8ic-LX-UPA"
      },
      "source": [
        "### Flower client\n",
        "\n",
        "To implement the Flower client, we (again) create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`. Here, we also pass the `cid` to the client and use it log additional details:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yltubwt_-UPB"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKG9UV31-UPB"
      },
      "source": [
        "## Strategy customization\n",
        "\n",
        "So far, everything should look familiar if you've worked through the introductory notebook. With that, we're ready to introduce a number of new features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJJzkeGb-UPB"
      },
      "source": [
        "### Server-side parameter **initialization**\n",
        "\n",
        "Flower, by default, initializes the global model by asking one random client for the initial parameters. In many cases, we want more control over parameter initialization though. Flower therefore allows you to directly pass the initial parameters to the Strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qEtobppK-UPB",
        "outputId": "be9b491e-acb4-4f05-c534-788ecb61f862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-05 07:54:16,030 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "2023-12-05 07:54:18,973\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-05 07:54:21,759 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 7857539483.0, 'object_store_memory': 3928769740.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 7857539483.0, 'object_store_memory': 3928769740.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0}\n",
            "INFO flwr 2023-12-05 07:54:21,769 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-05 07:54:21,773 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-12-05 07:54:21,776 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-12-05 07:54:21,806 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-12-05 07:54:21,813 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-05 07:54:21,818 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-12-05 07:54:21,824 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-12-05 07:54:21,829 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-05 07:54:21,836 | server.py:222 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 3 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(pid=498)\u001b[0m 2023-12-05 07:54:25.532817: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=498)\u001b[0m 2023-12-05 07:54:25.532898: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=498)\u001b[0m 2023-12-05 07:54:25.532943: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=498)\u001b[0m 2023-12-05 07:54:30.689982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=498)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=498)\u001b[0m Epoch 1: train loss 0.06382150202989578, accuracy 0.23466666666666666\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:54:50,168 | server.py:236 | fit_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:54:50,185 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 07:54:50,188 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m Epoch 1: train loss 0.06378521025180817, accuracy 0.23755555555555555\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:54:55,220 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:54:55,222 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 07:54:55,224 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m Epoch 1: train loss 0.05738864466547966, accuracy 0.32622222222222225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=498)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:55:10,153 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:55:10,167 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m Epoch 1: train loss 0.0568971149623394, accuracy 0.3268888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:55:16,913 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:55:16,915 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m Epoch 1: train loss 0.0539792999625206, accuracy 0.36866666666666664\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=498)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:55:30,024 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:55:30,048 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=496)\u001b[0m Epoch 1: train loss 0.053193312138319016, accuracy 0.3748888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:55:35,412 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "INFO flwr 2023-12-05 07:55:35,416 | server.py:153 | FL finished in 73.57949386\n",
            "INFO:flwr:FL finished in 73.57949386\n",
            "INFO flwr 2023-12-05 07:55:35,419 | app.py:226 | app_fit: losses_distributed [(1, 0.061749436934789015), (2, 0.05572592043876648), (3, 0.05245797618230184)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.061749436934789015), (2, 0.05572592043876648), (3, 0.05245797618230184)]\n",
            "INFO flwr 2023-12-05 07:55:35,422 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-12-05 07:55:35,423 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-12-05 07:55:35,425 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-12-05 07:55:35,426 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.061749436934789015\n",
              "\tround 2: 0.05572592043876648\n",
              "\tround 3: 0.05245797618230184"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "params = get_parameters(Net())\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_evaluate=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        ")\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sTp7jwi-UPB"
      },
      "source": [
        "Passing `initial_parameters` to the `FedAvg` strategy prevents Flower from asking one of the clients for the initial parameters. If we look closely, we can see that the logs do not show any calls to the `FlowerClient.get_parameters` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TiGv7P7-UPC"
      },
      "source": [
        "### Starting with a customized strategy\n",
        "\n",
        "We've seen the function `start_simulation` before. It accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate `num_clients`, the number of rounds `num_rounds`, and the strategy.\n",
        "\n",
        "The strategy encapsulates the federated learning approach/algorithm, for example, `FedAvg` or `FedAdagrad`. Let's try to use a different strategy this time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dGDftIVg-UPC",
        "outputId": "2baecb5b-c026-44b1-f4f2-a071c430b7ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-05 07:55:35,470 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "2023-12-05 07:55:40,247\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-05 07:55:44,460 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7823241216.0, 'object_store_memory': 3911620608.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7823241216.0, 'object_store_memory': 3911620608.0}\n",
            "INFO flwr 2023-12-05 07:55:44,472 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-05 07:55:44,491 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-12-05 07:55:44,493 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-12-05 07:55:44,546 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-12-05 07:55:44,552 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-05 07:55:44,556 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-12-05 07:55:44,557 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-12-05 07:55:44,558 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-05 07:55:44,559 | server.py:222 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 3 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(pid=1054)\u001b[0m 2023-12-05 07:55:49.174288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1054)\u001b[0m 2023-12-05 07:55:49.174368: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1054)\u001b[0m 2023-12-05 07:55:49.174409: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1054)\u001b[0m 2023-12-05 07:55:52.025167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m Epoch 1: train loss 0.06514626741409302, accuracy 0.21644444444444444\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1051)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 2] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:56:11,558 | server.py:236 | fit_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:56:11,579 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 07:56:11,595 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m Epoch 1: train loss 0.06479527801275253, accuracy 0.23466666666666666\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:56:18,147 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:56:18,151 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 07:56:18,154 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 7] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m Epoch 1: train loss 0.7623134255409241, accuracy 0.2777777777777778\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:56:31,618 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:56:31,634 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m Epoch 1: train loss 0.8284114003181458, accuracy 0.27244444444444443\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:56:36,408 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:56:36,411 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m Epoch 1: train loss 0.10471509397029877, accuracy 0.14266666666666666\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1051)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 6] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:56:50,280 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:56:50,296 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m Epoch 1: train loss 0.10178906470537186, accuracy 0.1411111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1054)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:56:55,146 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "INFO flwr 2023-12-05 07:56:55,149 | server.py:153 | FL finished in 70.59022740699999\n",
            "INFO:flwr:FL finished in 70.59022740699999\n",
            "INFO flwr 2023-12-05 07:56:55,151 | app.py:226 | app_fit: losses_distributed [(1, 5.811706273396809), (2, 0.6774957205454508), (3, 0.07631497796376546)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 5.811706273396809), (2, 0.6774957205454508), (3, 0.07631497796376546)]\n",
            "INFO flwr 2023-12-05 07:56:55,152 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-12-05 07:56:55,154 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-12-05 07:56:55,156 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-12-05 07:56:55,157 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 5.811706273396809\n",
              "\tround 2: 0.6774957205454508\n",
              "\tround 3: 0.07631497796376546"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Create FedAdam strategy\n",
        "strategy = fl.server.strategy.FedAdagrad(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_evaluate=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbRWeeoH-UPC"
      },
      "source": [
        "## Server-side parameter **evaluation**\n",
        "\n",
        "Flower can evaluate the aggregated model on the server-side or on the client-side. Client-side and server-side evaluation are similar in some ways, but different in others.\n",
        "\n",
        "**Centralized Evaluation** (or *server-side evaluation*) is conceptually simple: it works the same way that evaluation in centralized machine learning does. If there is a server-side dataset that can be used for evaluation purposes, then that's great. We can evaluate the newly aggregated model after each round of training without having to send the model to clients. We're also fortunate in the sense that our entire evaluation dataset is available at all times.\n",
        "\n",
        "**Federated Evaluation** (or *client-side evaluation*) is more complex, but also more powerful: it doesn't require a centralized dataset and allows us to evaluate models over a larger set of data, which often yields more realistic evaluation results. In fact, many scenarios require us to use **Federated Evaluation** if we want to get representative evaluation results at all. But this power comes at a cost: once we start to evaluate on the client side, we should be aware that our evaluation dataset can change over consecutive rounds of learning if those clients are not always available. Moreover, the dataset held by each client can also change over consecutive rounds. This can lead to evaluation results that are not stable, so even if we would not change the model, we'd see our evaluation results fluctuate over consecutive rounds.\n",
        "\n",
        "We've seen how federated evaluation works on the client side (i.e., by implementing the `evaluate` method in `FlowerClient`). Now let's see how we can evaluate aggregated model parameters on the server-side:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BEm5mftA-UPC"
      },
      "outputs": [],
      "source": [
        "# The `evaluate` function will be by Flower called after every round\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = Net().to(DEVICE)\n",
        "    valloader = valloaders[0]\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, valloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UMIiFdkL-UPD",
        "outputId": "0c4b1c38-bc71-43b7-e605-c7d772af7e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-05 07:56:55,210 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "2023-12-05 07:56:59,811\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-05 07:57:02,695 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 7815453083.0, 'object_store_memory': 3907726540.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 7815453083.0, 'object_store_memory': 3907726540.0}\n",
            "INFO flwr 2023-12-05 07:57:02,706 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-05 07:57:02,711 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-12-05 07:57:02,717 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-12-05 07:57:02,765 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-12-05 07:57:02,772 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-05 07:57:02,774 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-12-05 07:57:02,780 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-12-05 07:57:03,595 | server.py:94 | initial parameters (loss, other metrics): 0.07392096185684204, {'accuracy': 0.08}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 0.07392096185684204, {'accuracy': 0.08}\n",
            "INFO flwr 2023-12-05 07:57:03,598 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-05 07:57:03,600 | server.py:222 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07392096185684204 / accuracy 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1589)\u001b[0m 2023-12-05 07:57:06.804716: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1589)\u001b[0m 2023-12-05 07:57:06.804799: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1589)\u001b[0m 2023-12-05 07:57:06.804835: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 2023-12-05 07:57:11.243024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1591)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m Epoch 1: train loss 0.06463542580604553, accuracy 0.23666666666666666\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 1] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:57:30,581 | server.py:236 | fit_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:57:30,595 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "INFO flwr 2023-12-05 07:57:30,819 | server.py:125 | fit progress: (1, 0.062154918432235716, {'accuracy': 0.29}, 27.218780734999996)\n",
            "INFO:flwr:fit progress: (1, 0.062154918432235716, {'accuracy': 0.29}, 27.218780734999996)\n",
            "DEBUG flwr 2023-12-05 07:57:30,821 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.062154918432235716 / accuracy 0.29\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m Epoch 1: train loss 0.06419174373149872, accuracy 0.22977777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:57:35,696 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:57:35,698 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 07:57:35,701 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m Epoch 1: train loss 0.057147279381752014, accuracy 0.31977777777777777\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1591)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:57:50,063 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 3 results and 0 failures\n",
            "INFO flwr 2023-12-05 07:57:50,296 | server.py:125 | fit progress: (2, 0.05668581819534302, {'accuracy': 0.334}, 46.69608166699999)\n",
            "INFO:flwr:fit progress: (2, 0.05668581819534302, {'accuracy': 0.334}, 46.69608166699999)\n",
            "DEBUG flwr 2023-12-05 07:57:50,298 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m Epoch 1: train loss 0.05665380880236626, accuracy 0.3268888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "Server-side evaluation loss 0.05668581819534302 / accuracy 0.334\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:57:56,561 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:57:56,563 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m Epoch 1: train loss 0.05392584204673767, accuracy 0.35755555555555557\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1591)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 5] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:58:09,327 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 3 results and 0 failures\n",
            "INFO flwr 2023-12-05 07:58:09,678 | server.py:125 | fit progress: (3, 0.0532948784828186, {'accuracy': 0.368}, 66.07747057799997)\n",
            "INFO:flwr:fit progress: (3, 0.0532948784828186, {'accuracy': 0.368}, 66.07747057799997)\n",
            "DEBUG flwr 2023-12-05 07:58:09,687 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.0532948784828186 / accuracy 0.368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1589)\u001b[0m Epoch 1: train loss 0.053312718868255615, accuracy 0.3708888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:58:15,343 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "INFO flwr 2023-12-05 07:58:15,346 | server.py:153 | FL finished in 71.74595746099999\n",
            "INFO:flwr:FL finished in 71.74595746099999\n",
            "INFO flwr 2023-12-05 07:58:15,348 | app.py:226 | app_fit: losses_distributed [(1, 0.061408273061116535), (2, 0.05572245566050212), (3, 0.051477984110514324)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.061408273061116535), (2, 0.05572245566050212), (3, 0.051477984110514324)]\n",
            "INFO flwr 2023-12-05 07:58:15,349 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-12-05 07:58:15,353 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-12-05 07:58:15,355 | app.py:229 | app_fit: losses_centralized [(0, 0.07392096185684204), (1, 0.062154918432235716), (2, 0.05668581819534302), (3, 0.0532948784828186)]\n",
            "INFO:flwr:app_fit: losses_centralized [(0, 0.07392096185684204), (1, 0.062154918432235716), (2, 0.05668581819534302), (3, 0.0532948784828186)]\n",
            "INFO flwr 2023-12-05 07:58:15,356 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.08), (1, 0.29), (2, 0.334), (3, 0.368)]}\n",
            "INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.08), (1, 0.29), (2, 0.334), (3, 0.368)]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.061408273061116535\n",
              "\tround 2: 0.05572245566050212\n",
              "\tround 3: 0.051477984110514324\n",
              "History (loss, centralized):\n",
              "\tround 0: 0.07392096185684204\n",
              "\tround 1: 0.062154918432235716\n",
              "\tround 2: 0.05668581819534302\n",
              "\tround 3: 0.0532948784828186\n",
              "History (metrics, centralized):\n",
              "{'accuracy': [(0, 0.08), (1, 0.29), (2, 0.334), (3, 0.368)]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_evaluate=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        "    evaluate_fn=evaluate,  # Pass the evaluation function\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3rlR-uH-UPD"
      },
      "source": [
        "## Sending/receiving arbitrary values to/from clients\n",
        "\n",
        "In some situations, we want to configure client-side execution (training, evaluation) from the server-side. One example for that is the server asking the clients to train for a certain number of local epochs. Flower provides a way to send configuration values from the server to the clients using a dictionary. Let's look at an example where the clients receive values from the server through the `config` parameter in `fit` (`config` is also available in `evaluate`). The `fit` method receives the configuration dictionary through the `config` parameter and can then read values from this dictionary. In this example, it reads `server_round` and `local_epochs` and uses those values to improve the logging and configure the number of local training epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X2W4MR7E-UPE"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Read values from config\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.cid}, round {server_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk0DDRQu-UPE"
      },
      "source": [
        "So how can we  send this config dictionary from server to clients? The built-in Flower Strategies provide way to do this, and it works similarly to the way server-side evaluation works. We provide a function to the strategy, and the strategy calls this function for every round of federated learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BXsapRtn-UPE"
      },
      "outputs": [],
      "source": [
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\": 1 if server_round < 2 else 2,  #\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT0NpSgA-UPF"
      },
      "source": [
        "Next, we'll just pass this function to the FedAvg strategy before starting the simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A9YSjWBZ-UPF",
        "outputId": "97781f24-0377-449c-dca4-b787ce6642c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-05 07:58:15,412 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "2023-12-05 07:58:19,861\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-05 07:58:22,955 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7813160142.0, 'object_store_memory': 3906580070.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7813160142.0, 'object_store_memory': 3906580070.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0}\n",
            "INFO flwr 2023-12-05 07:58:22,962 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-05 07:58:22,963 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-12-05 07:58:22,965 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-12-05 07:58:23,026 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-12-05 07:58:23,030 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-05 07:58:23,041 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-12-05 07:58:23,045 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-12-05 07:58:24,409 | server.py:94 | initial parameters (loss, other metrics): 0.07366375494003295, {'accuracy': 0.092}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 0.07366375494003295, {'accuracy': 0.092}\n",
            "INFO flwr 2023-12-05 07:58:24,416 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-05 07:58:24,418 | server.py:222 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07366375494003295 / accuracy 0.092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2135)\u001b[0m 2023-12-05 07:58:28.544378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2135)\u001b[0m 2023-12-05 07:58:28.544454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2135)\u001b[0m 2023-12-05 07:58:28.544503: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2135)\u001b[0m 2023-12-05 07:58:31.722942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2135)\u001b[0m [Client 9, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2135)\u001b[0m Epoch 1: train loss 0.06503409892320633, accuracy 0.21533333333333332\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 7, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 1, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:58:51,221 | server.py:236 | fit_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:58:51,235 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "INFO flwr 2023-12-05 07:58:51,456 | server.py:125 | fit progress: (1, 0.06373861765861512, {'accuracy': 0.296}, 27.038496199000008)\n",
            "INFO:flwr:fit progress: (1, 0.06373861765861512, {'accuracy': 0.296}, 27.038496199000008)\n",
            "DEBUG flwr 2023-12-05 07:58:51,459 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.06373861765861512 / accuracy 0.296\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m Epoch 1: train loss 0.06580175459384918, accuracy 0.21911111111111112\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:58:58,097 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-12-05 07:58:58,100 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 07:58:58,103 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 3, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m Epoch 1: train loss 0.058032579720020294, accuracy 0.312\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2135)\u001b[0m [Client 0, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m Epoch 2: train loss 0.053026799112558365, accuracy 0.37533333333333335\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 8, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:59:20,257 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 3 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m Epoch 2: train loss 0.052283626049757004, accuracy 0.392\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-05 07:59:20,491 | server.py:125 | fit progress: (2, 0.0521415319442749, {'accuracy': 0.406}, 56.072749636000026)\n",
            "INFO:flwr:fit progress: (2, 0.0521415319442749, {'accuracy': 0.406}, 56.072749636000026)\n",
            "DEBUG flwr 2023-12-05 07:59:20,495 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.0521415319442749 / accuracy 0.406\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 6] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:59:26,979 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 07:59:26,982 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 6, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m Epoch 1: train loss 0.051831673830747604, accuracy 0.39155555555555555\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2135)\u001b[0m [Client 2, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m Epoch 2: train loss 0.04897875711321831, accuracy 0.42488888888888887\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 3, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:59:48,731 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 3 results and 0 failures\n",
            "INFO flwr 2023-12-05 07:59:48,964 | server.py:125 | fit progress: (3, 0.04856170272827148, {'accuracy': 0.454}, 84.546483121)\n",
            "INFO:flwr:fit progress: (3, 0.04856170272827148, {'accuracy': 0.454}, 84.546483121)\n",
            "DEBUG flwr 2023-12-05 07:59:48,967 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m Epoch 2: train loss 0.04790085554122925, accuracy 0.4431111111111111\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "Server-side evaluation loss 0.04856170272827148 / accuracy 0.454\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2136)\u001b[0m [Client 8] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 07:59:55,226 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "INFO flwr 2023-12-05 07:59:55,229 | server.py:153 | FL finished in 90.81105869100003\n",
            "INFO:flwr:FL finished in 90.81105869100003\n",
            "INFO flwr 2023-12-05 07:59:55,230 | app.py:226 | app_fit: losses_distributed [(1, 0.06335735988616943), (2, 0.05135376906394958), (3, 0.04802222681045532)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.06335735988616943), (2, 0.05135376906394958), (3, 0.04802222681045532)]\n",
            "INFO flwr 2023-12-05 07:59:55,234 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-12-05 07:59:55,236 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-12-05 07:59:55,239 | app.py:229 | app_fit: losses_centralized [(0, 0.07366375494003295), (1, 0.06373861765861512), (2, 0.0521415319442749), (3, 0.04856170272827148)]\n",
            "INFO:flwr:app_fit: losses_centralized [(0, 0.07366375494003295), (1, 0.06373861765861512), (2, 0.0521415319442749), (3, 0.04856170272827148)]\n",
            "INFO flwr 2023-12-05 07:59:55,241 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.092), (1, 0.296), (2, 0.406), (3, 0.454)]}\n",
            "INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.092), (1, 0.296), (2, 0.406), (3, 0.454)]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.06335735988616943\n",
              "\tround 2: 0.05135376906394958\n",
              "\tround 3: 0.04802222681045532\n",
              "History (loss, centralized):\n",
              "\tround 0: 0.07366375494003295\n",
              "\tround 1: 0.06373861765861512\n",
              "\tround 2: 0.0521415319442749\n",
              "\tround 3: 0.04856170272827148\n",
              "History (metrics, centralized):\n",
              "{'accuracy': [(0, 0.092), (1, 0.296), (2, 0.406), (3, 0.454)]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_evaluate=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        "    evaluate_fn=evaluate,\n",
        "    on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKUvhxS-UPF"
      },
      "source": [
        "As we can see, the client logs now include the current round of federated learning (which they read from the `config` dictionary). We can also configure local training to run for one epoch during the first and second round of federated learning, and then for two epochs during the third round.\n",
        "\n",
        "Clients can also return arbitrary values to the server. To do so, they return a dictionary from `fit` and/or `evaluate`. We have seen and used this concept throughout this notebook without mentioning it explicitly: our `FlowerClient` returns a dictionary containing a custom key/value pair as the third return value in `evaluate`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVwtURQj-UPF"
      },
      "source": [
        "## Scaling federated learning\n",
        "\n",
        "As a last step in this notebook, let's see how we can use Flower to experiment with a large number of clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "krsjqtWp-UPG",
        "outputId": "3fa6f1e6-f136-4cf5-be12-19ef9a0b38bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = 1000\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TD3pIKm-UPG"
      },
      "source": [
        "We now have 1000 partitions, each holding 45 training and 5 validation examples. Given that the number of training examples on each client is quite small, we should probably train the model a bit longer, so we configure the clients to perform 3 local training epochs. We should also adjust the fraction of clients selected for training during each round (we don't want all 1000 clients participating in every round), so we adjust `fraction_fit` to `0.05`, which means that only 5% of available clients (so 50 clients) will be selected for training each round:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jU-zRegf-UPG",
        "outputId": "bf6d9b67-af64-4a81-ec97-8f79047a1290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-05 07:59:57,265 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
            "2023-12-05 08:00:01,760\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-05 08:00:04,709 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 7811764224.0, 'object_store_memory': 3905882112.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 7811764224.0, 'object_store_memory': 3905882112.0, 'CPU': 2.0}\n",
            "INFO flwr 2023-12-05 08:00:04,720 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-05 08:00:04,723 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-12-05 08:00:04,727 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-12-05 08:00:04,785 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-12-05 08:00:04,795 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-05 08:00:04,802 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-12-05 08:00:04,807 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-12-05 08:00:04,813 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-05 08:00:04,821 | server.py:222 | fit_round 1: strategy sampled 25 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 25 clients (out of 1000)\n",
            "\u001b[2m\u001b[36m(pid=2769)\u001b[0m 2023-12-05 08:00:11.989720: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2769)\u001b[0m 2023-12-05 08:00:11.989800: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2769)\u001b[0m 2023-12-05 08:00:11.989845: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2768)\u001b[0m 2023-12-05 08:00:14.183811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 383, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 1: train loss 0.10201366990804672, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 2: train loss 0.10125135630369186, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 192, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.10104789584875107, accuracy 0.17777777777777778\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 285, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.10056347399950027, accuracy 0.2222222222222222\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 211, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.10067634284496307, accuracy 0.17777777777777778\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 547, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 1: train loss 0.10275238007307053, accuracy 0.044444444444444446\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 719, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 1: train loss 0.1028723418712616, accuracy 0.044444444444444446\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 391, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 1: train loss 0.10225079953670502, accuracy 0.044444444444444446\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 396, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 1: train loss 0.102460578083992, accuracy 0.08888888888888889\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 539, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 08:01:04,778 | server.py:236 | fit_round 1 received 25 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 25 results and 0 failures\n",
            "WARNING flwr 2023-12-05 08:01:04,844 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 08:01:04,846 | server.py:173 | evaluate_round 1: strategy sampled 50 clients (out of 1000)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 50 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 881] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.10095063596963882, accuracy 0.28888888888888886\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 593, round 1] fit, config: {'server_round': 1, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 488] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 342] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 837] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 926] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 798] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 884] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 749] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 734] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 847] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 549] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 565] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 512] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 281] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 438] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 08:02:30,117 | server.py:187 | evaluate_round 1 received 50 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 50 results and 0 failures\n",
            "WARNING flwr 2023-12-05 08:02:30,119 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-05 08:02:30,122 | server.py:222 | fit_round 2: strategy sampled 25 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 25 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 197, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 1: train loss 0.10186754912137985, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 2: train loss 0.10003069043159485, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.09857474267482758, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 698] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 161, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.0991915836930275, accuracy 0.17777777777777778\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 794, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 2: train loss 0.10108750313520432, accuracy 0.13333333333333333\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 983, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 1: train loss 0.10268445312976837, accuracy 0.13333333333333333\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 420, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.09733524173498154, accuracy 0.2\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 632, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.09970944374799728, accuracy 0.28888888888888886\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 970, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.09990056604146957, accuracy 0.35555555555555557\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 728, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.09934484958648682, accuracy 0.3111111111111111\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 08:03:19,257 | server.py:236 | fit_round 2 received 25 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 25 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 08:03:19,331 | server.py:173 | evaluate_round 2: strategy sampled 50 clients (out of 1000)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 50 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 602] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 280, round 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.0976206585764885, accuracy 0.4222222222222222\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 548] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 696] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 285] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 753] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 594] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 897] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 779] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 312] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 148] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 452] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 552] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 82] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 225] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 08:04:45,824 | server.py:187 | evaluate_round 2 received 50 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 50 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 08:04:45,826 | server.py:222 | fit_round 3: strategy sampled 25 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 25 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 929, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 406] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 1: train loss 0.10137572884559631, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 2: train loss 0.0996728464961052, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.09805518388748169, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 938, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.09310071915388107, accuracy 0.3333333333333333\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 484, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.09535480290651321, accuracy 0.3111111111111111\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 324, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.09644721448421478, accuracy 0.24444444444444444\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 546, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.0947929099202156, accuracy 0.4\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 839, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.09640412032604218, accuracy 0.26666666666666666\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 47, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m Epoch 3: train loss 0.0964859202504158, accuracy 0.17777777777777778\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 08:05:30,809 | server.py:236 | fit_round 3 received 25 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 25 results and 0 failures\n",
            "DEBUG flwr 2023-12-05 08:05:30,871 | server.py:173 | evaluate_round 3: strategy sampled 50 clients (out of 1000)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 50 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 452, round 3] fit, config: {'server_round': 3, 'local_epochs': 3}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 2: train loss 0.0979778915643692, accuracy 0.24444444444444444\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 633] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m Epoch 3: train loss 0.09684359282255173, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 203] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 478] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 166] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 796] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 529] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 153] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 744] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 443] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 842] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 39] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2768)\u001b[0m [Client 917] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2769)\u001b[0m [Client 794] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-05 08:06:58,049 | server.py:187 | evaluate_round 3 received 50 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 50 results and 0 failures\n",
            "INFO flwr 2023-12-05 08:06:58,051 | server.py:153 | FL finished in 413.22985575699994\n",
            "INFO:flwr:FL finished in 413.22985575699994\n",
            "INFO flwr 2023-12-05 08:06:58,054 | app.py:226 | app_fit: losses_distributed [(1, 0.4599130268096923), (2, 0.45515338897705077), (3, 0.44621464633941643)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.4599130268096923), (2, 0.45515338897705077), (3, 0.44621464633941643)]\n",
            "INFO flwr 2023-12-05 08:06:58,059 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-12-05 08:06:58,061 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-12-05 08:06:58,062 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-12-05 08:06:58,064 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.4599130268096923\n",
              "\tround 2: 0.45515338897705077\n",
              "\tround 3: 0.44621464633941643"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "def fit_config(server_round: int):\n",
        "    config = {\n",
        "        \"server_round\": server_round,\n",
        "        \"local_epochs\": 3,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.025,  # Train on 25 clients (each round)\n",
        "    fraction_evaluate=0.05,  # Evaluate on 50 clients (each round)\n",
        "    min_fit_clients=20,\n",
        "    min_evaluate_clients=40,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        "    on_fit_config_fn=fit_config,\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2PG9fVz-UPH"
      },
      "source": [
        "## Recap\n",
        "\n",
        "In this notebook, we've seen how we can gradually enhance our system by customizing the strategy, initializing parameters on the server side, choosing a different strategy, and evaluating models on the server-side. That's quite a bit of flexibility with so little code, right?\n",
        "\n",
        "In the later sections, we've seen how we can communicate arbitrary values between server and clients to fully customize client-side execution. With that capability, we built a large-scale Federated Learning simulation using the Flower Virtual Client Engine and ran an experiment involving 1000 clients in the same workload - all in a Jupyter Notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV-zNHoD-UPI"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Before you continue, make sure to join the Flower community on Slack: [Join Slack](https://flower.dev/join-slack/)\n",
        "\n",
        "There's a dedicated `#questions` channel if you need help, but we'd also love to hear who you are in `#introductions`!\n",
        "\n",
        "The [Flower Federated Learning Tutorial - Part 3](https://flower.dev/docs/framework/tutorial-build-a-strategy-from-scratch-pytorch.html) shows how to build a fully custom `Strategy` from scratch."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Flower-2-Strategies-in-FL-PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('flower-3.7.12')",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}